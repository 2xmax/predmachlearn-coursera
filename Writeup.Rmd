---
title: "Writeup"
output: html_document
---

Motivation
===============================

The goal of this work is to predict human activities by collected data using devices such as Jawbone Up, Nike FuelBand, and Fitbit. The approach of research is based upon this paper <http://groupware.les.inf.puc-rio.br/har>.

Environment initialization
===============================
Let us load these packages
```{r}
library(dplyr)
library(caret)
library(randomForest)
```

And set some seed to make the experiment reproducible

```{r}
set.seed(42)
```

Obtaining and preprocessing data
===============================

```{r}
if (!file.exists("pml-training.csv")){
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "pml-training.csv", method="curl")  
}

# remove na and empty values from dataset
raw <- read.csv("pml-training.csv", na.strings = c("NA",""), stringsAsFactors = FALSE)
```

The original dataset have a lot of noise, let us clean it.
```{r}
cleanupData = function(raw){
  # remove unrelated fields from model
  cleaned <- subset(raw, select = -c(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, num_window))
  # there are a lot of columns with missing data, throw them up
  naThreshold = as.integer(nrow(raw) * 0.5)
  cleaned <- subset(cleaned, select = -which(colSums(is.na(cleaned)) > naThreshold))
  cleaned
}

data = cleanupData(raw)
```

Prediction
=============================

Let us split train and test crossvalidation set in typical proportion, let us say, in 70%/30%.
```{r}
data$classe <- as.factor(data$classe)
testIndex = createDataPartition(data$classe, p = 0.7, list=FALSE)
train = data[-testIndex,]
test = data[testIndex,]

```

Based on the paper's rocommendations, we are going to use random forest classification algorithm.
```{r}
predictor <- randomForest(classe ~ ., data = train)
```

N.B.: for simplicity, single thread code has been provided. It can be run in parallel, using doParallel package (TBD: provide example).

Conclusion
=============================

```{r}
testPred <- predict(predictor, newdata = test)
accurancy = confusionMatrix(testPred$classe, testPred)$overall[1]
```

It can be concluded that the algorithm's accurancy is equal to 98.43% and the out-of-sample error is 1.56%.
